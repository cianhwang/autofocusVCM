{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "import numpy as np\n",
    "#import h5py\n",
    "#import tensorflow as tf\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "#from scipy import signal\n",
    "from keras.layers import Input,Conv2D,Concatenate,Flatten,Dense,LeakyReLU,Dropout, ReLU\n",
    "from keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.activations import relu\n",
    "from keras.optimizers import Adam\n",
    "# from tensorflow.python.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "#from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#from tensorflow.python.keras.layers import Conv2D, MaxPooling2D\n",
    "#from tensorflow.python.keras.models import Sequential\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "# set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = 2\n",
    "d_min = 1\n",
    "d_max = 10\n",
    "blur_filter_size = 11\n",
    "blur_range = 10\n",
    "image_size = 512\n",
    "epochs = 300\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_path = 'train_data_uint8_512_10000_vcm_alpha.npy'\n",
    "# test_data_path = 'real_data_uint8_512_vcm_10000_alpha.npy'\n",
    "# train_label_path = 'train_label_uint8_512_10000_vcm_alpha.npy'\n",
    "# test_label_path = 'real_label_uint8_512_vcm_10000_alpha.npy'\n",
    "\n",
    "train_data_path = 'train_data_8000_raw.npy'\n",
    "test_data_path = 'real_data_2000_raw.npy'\n",
    "train_label_path = 'train_label_8000_raw.npy'\n",
    "test_label_path = 'real_label_2000_raw.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(train_data_path)#[:10000, :, :, :]\n",
    "test_data = np.load(test_data_path)\n",
    "\n",
    "train_label = np.load(train_label_path)#[:10000, :]\n",
    "test_label = np.load(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 512, 512, 1)\n",
      "(8000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "# test_data = test_data[1::2, :, :, :]\n",
    "# test_label = test_label[1::2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data -= np.mean(train_data, axis = 0)\n",
    "train_data /= np.std(train_data, axis = 0)\n",
    "test_data -= np.mean(test_data, axis = 0)\n",
    "test_data /= np.std(test_data, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pre_normalize(im):\n",
    "#     # https://www.learnopencv.com/image-quality-assessment-brisque/\n",
    "#     blurred = cv2.GaussianBlur(im, (7, 7), 1.166) # apply gaussian blur to the image\n",
    "#     blurred_sq = blurred * blurred\n",
    "#     sigma = cv2.GaussianBlur(im * im, (7, 7), 1.166) \n",
    "#     sigma = (sigma - blurred_sq) ** 0.5\n",
    "#     sigma = sigma + 1.0/255 # to make sure the denominator doesn't give DivideByZero Exception\n",
    "#     structdis = (im - blurred)/sigma # final MSCN(i, j) image\n",
    "#     t = im - blurred\n",
    "#     t = (t-t.min())/(t.max() - t.min())\n",
    "#     return t\n",
    "\n",
    "# for iii in range(train_data.shape[0]):\n",
    "#     train_data[iii, :, :, 0] = pre_normalize(train_data[iii, :, :, 0].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# for idx in range(10):\n",
    "#     plt.imshow(train_data[idx, :, :, 0].astype(np.float32))\n",
    "#     plt.show()\n",
    "#     print(train_label[idx, :])\n",
    "# print(train_data.dtype)\n",
    "# # batch_features = np.zeros((image_size//2, image_size//2, 4))\n",
    "# # batch_features[:, :, 0] = train_data[idx, 1::2, ::2, 0]\n",
    "# # batch_features[:, :, 1] = train_data[idx, ::2, ::2, 0]\n",
    "# # batch_features[:, :, 2] = train_data[idx, 1::2, 1::2, 0]\n",
    "# # batch_features[:, :, 3] = train_data[idx, ::2, 1::2, 0]\n",
    "# # plt.imshow(batch_features[:, :, 3]*16383)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(test_data[idx, :, :, 0])\n",
    "# print(test_label[idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "input_image1 = Input(shape=(512, 512, 4), name = \"input\")\n",
    "\n",
    "layer1_1 = Conv2D(4, (8, 8), 8,padding='valid',activation=relu, name=\"Conv1_1\")(input_image1)\n",
    "#layer1_1 = LeakyReLU(0.1)(layer1_1)\n",
    "\n",
    "layer2_1 = Conv2D(8, (4, 4), 4,padding='valid',activation=relu, name=\"Conv2_1\")(layer1_1)\n",
    "#layer2_1 = LeakyReLU(0.1)(layer2_1)\n",
    "\n",
    "layer3_1 = Conv2D(8, (4, 4), 4,padding='valid',activation=relu, name=\"Conv3_1\")(layer2_1)\n",
    "\n",
    "flattened = Flatten(name=\"flat\")(layer3_1)\n",
    "dense1 = Dense(1024, name=\"d1\")(flattened)\n",
    "ReLU1 = LeakyReLU(0.1, name=\"lr1\")(dense1)\n",
    "dp1 = Dropout(0.5)(ReLU1)\n",
    "\n",
    "dense2 = Dense(256, name=\"d2\")(dp1)\n",
    "ReLU2 = LeakyReLU(0.1, name=\"lr2\")(dense2)\n",
    "dp2 = Dropout(0.5)(ReLU2)\n",
    "\n",
    "dense3 = Dense(64, name=\"d3\")(dp2)\n",
    "ReLU3 = LeakyReLU(0.1, name=\"lr3\")(dense3)\n",
    "dp3 = Dropout(0.5)(ReLU3)\n",
    "\n",
    "output_position = Dense(1, name=\"out\")(dp3)\n",
    "print(output_position)\n",
    "\n",
    "model = Model(inputs=input_image1, outputs=output_position)\n",
    "model.summary()\n",
    "\n",
    "tcbc = TensorBoard(log_dir='1')\n",
    "\n",
    "filepath=\"raw_models/gen/n_{epoch:03d}-{val_loss:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, mode='max',period=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(features, labels, batch_size):\n",
    "    while True:\n",
    "        for i in np.arange(0, features.shape[0] - batch_size, batch_size):\n",
    "            # choose random index in features\n",
    "            ################!!!\n",
    "#             batch_features = np.zeros((batch_size, image_size//2, image_size//2, 4))\n",
    "#             batch_features[:, :, :, 0] = features[i:i+batch_size, 1::2, ::2, 0]\n",
    "#             batch_features[:, :, :, 1] = features[i:i+batch_size, ::2, ::2, 0]\n",
    "#             batch_features[:, :, :, 2] = features[i:i+batch_size, 1::2, 1::2, 0]\n",
    "#             batch_features[:, :, :, 3] = features[i:i+batch_size, ::2, 1::2, 0]\n",
    "            batch_features = np.zeros((batch_size, image_size, image_size, 1))\n",
    "            batch_features = features[i:i+batch_size, :, :, :]\n",
    "            batch_features = batch_features.astype('float16')#/255###########################\n",
    "            batch_labels = abs(labels[i:i+batch_size, 1:2] - labels[i:i+batch_size, :1])*100\n",
    "            yield (batch_features, batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0001)\n",
    "model.compile(loss='mse', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_data, train_label, test_size=0.01, random_state=2233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(train_data[:,:,:,0:1].astype('float16')/255.0, abs(train_label[:,1:2]-train_label[:,0:1])/100, \n",
    "#           epochs = 100,batch_size = batch_size, #validation_split=0.2,\n",
    "#           validation_data=(test_data[:,:,:,0:1].astype('float16')/255.0, abs(test_label[:,1:2]-test_label[:,0:1])/100), \n",
    "#           verbose=1, callbacks = [tcbc, checkpoint])\n",
    "history = model.fit_generator(data_gen(X_train, y_train, batch_size), \n",
    "                    steps_per_epoch = X_train.shape[0]/batch_size, epochs = epochs,\n",
    "                    validation_data=data_gen(test_data, test_label, batch_size), \n",
    "                    validation_steps = batch_size,verbose=1)#, callbacks = [tcbc, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('auto_hist', 'wb') as file_pi:\n",
    "#     pickle.dump(history.history, file_pi)\n",
    "with open(r\"raw_models/trainHistoryDict\", \"rb\") as input_file:\n",
    "    history = pickle.load(input_file)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt.plot(history['acc'])\n",
    "# plt.plot(history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.scatter([88], history['val_loss'][88], marker='*', c = 'r')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('my_model_512.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_label[:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.keras.models import load_model\n",
    "# model = load_model('raw_models/120-0.494.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# idxx = 89\n",
    "# plt.imshow(test_data[idxx, :, :, 0])\n",
    "# print(test_label[idxx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(test_data[idxx:idxx+1, :, :, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# batch_features_ = np.ones(y_test.shape)\n",
    "# for i in range(2000//64-1): #\n",
    "#     batch_features = X_test[64*i:64*i+64,:,:,:]\n",
    "# #    batch_features = np.zeros((64, image_size//2, image_size//2, 4))\n",
    "# #     batch_features[:, :, :, 0] = X_test[64*i:64*i+64, 1::2, ::2, 0]\n",
    "# #     batch_features[:, :, :, 1] = X_test[64*i:64*i+64, ::2, ::2, 0]\n",
    "# #     batch_features[:, :, :, 2] = X_test[64*i:64*i+64, 1::2, 1::2, 0]\n",
    "# #     batch_features[:, :, :, 3] = X_test[64*i:64*i+64, ::2, 1::2, 0]\n",
    "#     batch_features_[64*i:64*i+64, :] = model.predict(batch_features)\n",
    "\n",
    "# plt.scatter(abs(y_test[:1936, 0] - y_test[:1936, 1])*100, batch_features_[:1936, 0] - abs(y_test[:1936, 0] - y_test[:1936, 1])*100, color='black', s = 0.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(6000//64-1): #\n",
    "#     train_pred[64*i:64*i+64, :, :, :] = model.predict(X_train[64*i:64*i+64, :, :, :1])\n",
    "#     plt.scatter(abs(y_train[64*i:64*i+64, 0] - y_train[64*i:64*i+64, 1])*100, train_pred[:, 0] - abs(y_train[64*i:64*i+64, 0] - y_train[64*i:64*i+64, 1])*100, color='black', s = 0.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred[test_pred<0]= 0\n",
    "# print(test_pred[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# plt.imshow(test_data[0, :, :, 0])\n",
    "# print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(abs(test_label[:, 0] - test_label[:, 1]), test_pred[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
